{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730abb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Environment Setup\n",
    "# =========================\n",
    "\n",
    "# Install uv for dependency management\n",
    "!pip install -q uv\n",
    "# Retrieve the list of dependencies\n",
    "!wget https://raw.githubusercontent.com/oliviermeslin/crospint/main/pyproject.toml\n",
    "# Install dependencies\n",
    "!uv pip install -r pyproject.toml\n",
    "# Install crospint\n",
    "!uv pip install crospint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d145fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# The notebook starts here\n",
    "# =========================\n",
    "\n",
    "# Modules for data manipulation\n",
    "import polars as pl\n",
    "from polars import col as c\n",
    "import numpy as np\n",
    "\n",
    "# Modules for machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import lightgbm\n",
    "\n",
    "# Import the model\n",
    "from crospint.housing_prices import TwoStepsModel, \\\n",
    "    calibrate_model, train_calibration_model\n",
    "\n",
    "# Import plotting functions\n",
    "from plotnine import *\n",
    "from mizani.formatters import percent_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a96ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to retrieve the data from S3\n",
    "def retrieve_transaction_data(type_housing_unit):\n",
    "    assert type_housing_unit in[\"houses\", \"flats\"], \"type_housing_unit must be either 'houses' or 'flats'\"\n",
    "    df = (\n",
    "        pl.read_parquet(\n",
    "            f\"https://minio.lab.sspcloud.fr/oliviermeslin/diffusion/DVF/transaction_data_{type_housing_unit}_open_data.parquet\"\n",
    "        )\n",
    "    )\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50c0884",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download data from S3\n",
    "df_transactions = retrieve_transaction_data(\"houses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e420390",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa46935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the train-test split\n",
    "train_val, test = train_test_split(\n",
    "    df_transactions,\n",
    "    test_size=0.15,\n",
    "    random_state=20230516\n",
    ")\n",
    "\n",
    "# Perform the train-validation split\n",
    "train, val = train_test_split(\n",
    "    train_val,\n",
    "    train_size=0.80,\n",
    "    random_state=20230516\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5658221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model hyperparameters\n",
    "parameters_price_model = {\n",
    "    \"coord_rotation__coordinates_names\": (\"x\", \"y\"),\n",
    "    \"coord_rotation__number_axis\": 11,\n",
    "    \"date_conversion__date_name\": \"transaction_date\",\n",
    "    \"date_conversion__reference_date\": \"2014-01-01\",\n",
    "    \"model__seed\": 20230516,\n",
    "    \"model__n_estimators\": 1000,\n",
    "    \"model__learning_rate\": 0.2,\n",
    "    \"model__num_leaves\": 1023,\n",
    "    \"model__max_depth\": 15,\n",
    "    \"model__max_bins\": 3000,\n",
    "    \"model__min_child_samples\": 75,\n",
    "    \"model__lambda_l2\": 20,\n",
    "    \"model__min_gain_to_split\": 0.0006,\n",
    "    \"model__bagging_fraction\": 1,\n",
    "    \"model__bagging_freq\": 0,\n",
    "    \"model__feature_fraction\": 0.7\n",
    "}\n",
    "target_variable_name = \"transaction_amount\"\n",
    "model_features = ['floor_area', 'transaction_date', 'x', 'y', \"seashore_distance\"]\n",
    "floor_area_variable = \"floor_area\"\n",
    "calibration_variables = ['transaction_year', 'transaction_month', 'id_departement', 'floor_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "price_model = TwoStepsModel(\n",
    "    model=lightgbm.LGBMRegressor(verbose=-1),\n",
    "    log_transform=True,\n",
    "    price_sq_meter=True,\n",
    "    presence_coordinates=True,\n",
    "    floor_area_name=floor_area_variable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ecdf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass parameters to the models\n",
    "price_model.pipe.set_params(\n",
    "    **parameters_price_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f262692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "price_model.fit(\n",
    "    X=train,\n",
    "    y=train[target_variable_name].to_numpy().ravel(),\n",
    "    model_features=model_features,\n",
    "    X_val=val,\n",
    "    y_val=val[target_variable_name].to_numpy().ravel(),\n",
    "    early_stopping_rounds=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e1027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate the model\n",
    "calibration_success = False\n",
    "convergence_rate = 0\n",
    "while not calibration_success:\n",
    "    convergence_rate += 1e-3\n",
    "    print(convergence_rate)\n",
    "    price_model, calibration_success = calibrate_model(\n",
    "        model=price_model,\n",
    "        X=None, # the validation set is used as calibration set by default\n",
    "        y=None, # the validation set is used as calibration set by default\n",
    "        calibration_variables=calibration_variables,\n",
    "        convergence_rate=convergence_rate,\n",
    "        max_iter=50,\n",
    "        verbose=True\n",
    "    )\n",
    "print(f\"    The model was calibrated with threshold {convergence_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c47be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the calibration model\n",
    "price_model = train_calibration_model(\n",
    "    price_model,\n",
    "    calibration_model=lightgbm.LGBMRegressor(\n",
    "        n_estimators=100,\n",
    "        num_leaves=1023,\n",
    "        max_depth=12,\n",
    "        learning_rate=0.5,\n",
    "        min_child_samples=20,\n",
    "        max_bins=10000,\n",
    "        random_state=123456,\n",
    "        verbose=-1\n",
    "    ),\n",
    "    r2_threshold=0.98,\n",
    "    evaluation_period=5,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c6f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions on the test set\n",
    "raw_predictions = price_model.predict(\n",
    "    test,\n",
    "    add_retransformation_correction=True,\n",
    "    retransformation_method=\"Miller\"\n",
    ")\n",
    "cal_predictions = price_model.predict(\n",
    "    test,\n",
    "    add_retransformation_correction=True,\n",
    "    retransformation_method=\"calibration\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5fac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add prediction to the test set\n",
    "test2 = (\n",
    "    test\n",
    "    .with_columns(\n",
    "        raw_prediction = pl.Series(raw_predictions),\n",
    "        cal_prediction = pl.Series(cal_predictions)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae8ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics on predictive power\n",
    "r2_raw = r2_score(np.log(test2[\"transaction_amount\"]), np.log(test2[\"raw_prediction\"] / np.exp(price_model.RMSE**2 / 2)))\n",
    "share_below20_raw = test2.filter((c.raw_prediction / c.transaction_amount - 1).abs() < 0.2).shape[0] / test.shape[0]\n",
    "r2_cal = r2_score(np.log(test2[\"transaction_amount\"]), np.log(test2[\"cal_prediction\"]))\n",
    "share_below20_cal = test2.filter((c.cal_prediction / c.transaction_amount - 1).abs() < 0.2).shape[0] / test.shape[0]\n",
    "print(f\"The R² of the model with Miller's correction is {r2_raw: .3f}; {share_below20_raw: .1%} of observations are predicted with an absolute error of less than 20%.\")\n",
    "print(f\"The R² of the calibrated model is {r2_cal: .3f}; {share_below20_cal: .1%} of observations are predicted with an absolute error of less than 20%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3b8edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define quantiles\n",
    "nb_quantiles = 200\n",
    "probs = np.arange(1, nb_quantiles) / nb_quantiles\n",
    "\n",
    "# Compute true and predicted quantiles\n",
    "quantiles = (\n",
    "    test2.select(\n",
    "        pl.concat_list([\n",
    "            pl.struct(\n",
    "                pl.lit(p).alias(\"quantile\"),\n",
    "                pl.col(\"transaction_amount\").quantile(p, interpolation=\"nearest\").alias(\"quantile_true\"),\n",
    "                pl.col(\"raw_prediction\").quantile(p, interpolation=\"nearest\").alias(\"quantile_raw_prediction\"),\n",
    "                pl.col(\"cal_prediction\").quantile(p, interpolation=\"nearest\").alias(\"quantile_cal_prediction\"),\n",
    "            )\n",
    "            for p in probs\n",
    "        ]).alias(\"data\")\n",
    "    )\n",
    "    .explode(\"data\")\n",
    "    .unnest(\"data\")\n",
    "    # .with_columns(\n",
    "    #     pl.format(\"P{}\", (pl.col(\"percentile\") * nb_quantiles).cast(pl.Float32))\n",
    "    #     .alias(\"percentile\")\n",
    "    # )\n",
    "    .select([\"quantile\", \"quantile_true\", \"quantile_raw_prediction\", \"quantile_cal_prediction\"])\n",
    "    .with_columns(\n",
    "        ratio_raw = c.quantile_raw_prediction / c.quantile_true,\n",
    "        ratio_cal = c.quantile_cal_prediction / c.quantile_true\n",
    "    )\n",
    "    .select(\"quantile\", \"quantile_true\", \"ratio_raw\", \"ratio_cal\")\n",
    "    .unpivot(\n",
    "       index = [\"quantile\", \"quantile_true\"]\n",
    "    )\n",
    "    .with_columns(\n",
    "        model_label = pl.when(c.variable==\"ratio_raw\").then(pl.lit(\"Model with Miller's correction\")).otherwise(pl.lit(\"Calibrated model\"))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227317dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the calibration curve on the test set\n",
    "(\n",
    "    ggplot(quantiles) +\n",
    "    geom_line(aes(x = \"quantile_true\", y = \"value\", color = \"model_label\"), size = 1) +\n",
    "    labs(\n",
    "        x = \"True quantile value\",\n",
    "        y = \"Ratio predicted quantile/true quantile\",\n",
    "        color = \"Model\"\n",
    "    ) +\\\n",
    "    scale_x_log10() +\n",
    "    scale_color_cmap_d(cmap_name=\"viridis\") +\n",
    "    theme(legend_position=\"bottom\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb0ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute WMAPB to measure conditional biases\n",
    "variables_wmapb = ['transaction_year', 'transaction_month', 'id_departement', 'floor_area']\n",
    "wmapb_results = (\n",
    "        pl.concat(\n",
    "        [\n",
    "            (\n",
    "                test2\n",
    "                .group_by(var)\n",
    "                .agg(\n",
    "                    nb_observations = pl.len(),\n",
    "                    bias_raw = (c.raw_prediction.sum() / c.transaction_amount.sum() - 1),\n",
    "                    bias_cal = (c.cal_prediction.sum() / c.transaction_amount.sum() - 1)\n",
    "                )\n",
    "                .select(\n",
    "                    variable_wmapb = pl.lit(var),\n",
    "                    wmapb_raw = (c.nb_observations * c.bias_raw.abs()).sum() / c.nb_observations.sum(),\n",
    "                    wmapb_cal = (c.nb_observations * c.bias_cal.abs()).sum() / c.nb_observations.sum()\n",
    "                )\n",
    "            )\n",
    "            for var in variables_wmapb\n",
    "        ]\n",
    "    )\n",
    "    .unpivot(\n",
    "       index = [\"variable_wmapb\"]\n",
    "    )\n",
    "    .with_columns(\n",
    "        model_label = pl.when(c.variable==\"wmapb_raw\").then(pl.lit(\"Model with Miller's correction\")).otherwise(pl.lit(\"Calibrated model\"))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed42985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot WMAPB\n",
    "(\n",
    "    ggplot(wmapb_results) +\n",
    "    geom_bar(\n",
    "        aes(x = \"variable_wmapb\", y = \"value\", fill = \"model_label\"),\n",
    "        stat = \"identity\", position = \"dodge\"\n",
    "    ) +\n",
    "    labs(\n",
    "        x = \"Variable\",\n",
    "        y = \"WMAPB metric\",\n",
    "        fill = \"Model\"\n",
    "    ) +\\\n",
    "    scale_fill_cmap_d(cmap_name=\"viridis\") +\n",
    "    scale_y_continuous(labels=percent_format()) +\n",
    "    theme(legend_position=\"bottom\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf88acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time consistency\n",
    "time_trends = (\n",
    "    test2\n",
    "    .group_by(\"transaction_year\")\n",
    "    .agg(\n",
    "        ratio_raw = (c.raw_prediction.sum() / c.transaction_amount.sum()),\n",
    "        ratio_cal = (c.cal_prediction.sum() / c.transaction_amount.sum())\n",
    "    )\n",
    "    .unpivot(\n",
    "       index = [\"transaction_year\"]\n",
    "    )\n",
    "    .with_columns(\n",
    "        model_label = pl.when(c.variable==\"ratio_raw\").then(pl.lit(\"Model with Miller's correction\")).otherwise(pl.lit(\"Calibrated model\"))\n",
    "    )\n",
    "    .sort(\"transaction_year\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f2b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time trends\n",
    "(\n",
    "    ggplot(time_trends) +\n",
    "    geom_line(\n",
    "        aes(x = \"transaction_year\", y = \"value\", color = \"model_label\"), size = 1\n",
    "    ) +\n",
    "    labs(\n",
    "        x = \"Year\",\n",
    "        y = \"Ratio total predicted amounts /\\ntotal observed amounts\",\n",
    "        color = \"Model\"\n",
    "    ) +\\\n",
    "    scale_color_cmap_d(cmap_name=\"viridis\") +\n",
    "    scale_y_continuous(labels=percent_format(), limits = (0.95, 1.05)) +\n",
    "    theme(legend_position=\"bottom\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e91b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
