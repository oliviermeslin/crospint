{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a2469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Environment Setup\n",
    "# =========================\n",
    "\n",
    "# Install uv for dependency management\n",
    "!pip install -q uv\n",
    "# Retrieve the list of dependencies\n",
    "!wget https://raw.githubusercontent.com/oliviermeslin/crospint/main/pyproject.toml\n",
    "# Install dependencies\n",
    "!uv pip install -r pyproject.toml\n",
    "# Install crospint\n",
    "!uv pip install crospint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f921cf3",
   "metadata": {},
   "source": [
    "## What is this notebook about?\n",
    "\n",
    "This notebook illustrates the _conditional tail removal_ procedure defined in [Meslin, 2026]. \n",
    "\n",
    "⚠️⚠️⚠️\n",
    "This notebook is computationally intensive. Read the section on \"How to use this notebook\" before running the code.  \n",
    "⚠️⚠️⚠️\n",
    "\n",
    "### The CTR procedure\n",
    "\n",
    "The CTR procedure has four steps:\n",
    "\n",
    "- A random forest is trained to predict the (log) price per square meter $p_{it}$. This model writes: $p_{it} = h\\left(g\\left(x_{i}, y_{i}\\right), d_i, t, S_i\\right)$ with $p_{it}$ the log-price per square meter, $x_i, y_i$ the coordinates of housing unit $i$, $d_i$ the shortest distance to the sea, $t$ the transaction date and $S_i$ the floor area of the housing unit. Coordinate rotation $g$ is applied to coordinates before training the model.\n",
    "- Once the random forest is trained, residuals are computed for all transactions as the difference between the (log) price per square meter and the model out-of-bag prediction: $\\hat{\\epsilon}_{it} = p_{it} - \\hat{h}^{\\text{OOB}}\\left(g\\left(x_{i}, y_{i}\\right), d_i, t, S_i\\right)$\n",
    "- Statistical tests are conducted to determine which distribution of reference best fits the distribution of residuals. In the present case, the distribution residuals matches closely an asymmetric Laplace distribution.\n",
    "- Comparing the score distribution with the distribution of reference using a quantile-quantile plot allows identifying thresholds where the tails of the score distribution start to diverge from the reference distribution.\n",
    "\n",
    "### How to use this notebook\n",
    "\n",
    "In this notebook, the model hyperparameters are set to values compatible with proper outlier detection, but may induce a long training time as training random forest is computationally demanding, and resources on Colab are limited. If you just want to make a quick test, I advise you to adjust the hyperparameters so that training is much faster:\n",
    "\n",
    "- Reduce `model__n_estimators` to 40;\n",
    "- Increase `model__min_samples_split` to 200;\n",
    "- Increase `model__min_samples_leaf` to 100.\n",
    "\n",
    "At some point, you can use data on `houses` or `flats`. Modify the line `df_transactions = retrieve_transaction_data(\"flats\")` depending on what you want to look at.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d145fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# The notebook starts here\n",
    "# =========================\n",
    "\n",
    "import polars as pl\n",
    "from polars import col as c\n",
    "import numpy as np\n",
    "\n",
    "# Modules for modelling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from crospint import create_model_pipeline\n",
    "\n",
    "# Measuring execution time\n",
    "import time\n",
    "\n",
    "# Function to model distributions\n",
    "from scipy.stats import laplace_asymmetric\n",
    "\n",
    "# Import plotting functions\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0adb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to retrieve the data from S3\n",
    "def retrieve_transaction_data(type_housing_unit):\n",
    "    assert type_housing_unit in[\"houses\", \"flats\"], \"type_housing_unit must be either 'houses' or 'flats'\"\n",
    "    df = (\n",
    "        pl.read_parquet(\n",
    "            f\"https://minio.lab.sspcloud.fr/oliviermeslin/diffusion/DVF/transaction_data_{type_housing_unit}_open_data.parquet\"\n",
    "        )\n",
    "    )\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50c0884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from S3\n",
    "df_transactions = retrieve_transaction_data(\"flats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e420390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show transactions\n",
    "df_transactions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa46935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the target\n",
    "df_transactions = (\n",
    "    df_transactions\n",
    "    .with_columns(\n",
    "        log_price_sqm = np.log(c.transaction_amount/c.floor_area)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99123ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5658221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model hyperparameters\n",
    "params = {\n",
    "    \"coord_rotation__coordinates_names\": (\"x\", \"y\"),\n",
    "    \"coord_rotation__number_axis\": 11,\n",
    "    \"date_conversion__date_name\": \"transaction_date\",\n",
    "    \"date_conversion__reference_date\": \"2010-01-01\",\n",
    "    \"model__n_estimators\": 120,\n",
    "    \"model__min_samples_split\": 20,\n",
    "    \"model__min_samples_leaf\": 10,\n",
    "    \"model__n_jobs\": -1,\n",
    "    \"model__max_features\": 0.4,\n",
    "    \"model__verbose\": 3,\n",
    "    \"model__oob_score\": True,\n",
    "    \"model__random_state\": 20230516\n",
    "}\n",
    "model_features = ['floor_area', 'transaction_date', 'x', 'y', 'seashore_distance']\n",
    "target_variable_name = \"log_price_sqm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = create_model_pipeline(model=RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ecdf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass parameters to the models\n",
    "model.set_params(\n",
    "    **params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f262692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "start_time = time.perf_counter()\n",
    "model.fit(\n",
    "    df_transactions.select(model_features),\n",
    "    df_transactions.select(target_variable_name).to_numpy().ravel()\n",
    ")\n",
    "end_time = time.perf_counter()\n",
    "print(f'    Training of the outlier detection model took {end_time - start_time}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2518c91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model[\"model\"].oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e1027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the OOB prediction to the data and compute residuals\n",
    "df_transactions2 = (\n",
    "    df_transactions\n",
    "    .with_columns(\n",
    "        price_prediction_oob = pl.Series(model[\"model\"].oob_prediction_)\n",
    "    )\n",
    "    .with_columns(\n",
    "        residual_oob = pl.col(target_variable_name) - c.price_prediction_oob\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c47be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an asymmetric Laplace distribution\n",
    "kappa_la, loc_la, scale_la = laplace_asymmetric.fit(\n",
    "    df_transactions2[\"residual_oob\"]\n",
    ")\n",
    "print(kappa_la, loc_la, scale_la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe14bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the distribution of residuals with an asymmetric Laplace Distribution\n",
    "# and find appropriate thresholds for cleaning\n",
    "x_r1 = [q / 10000 for q in range(1, 10000)]\n",
    "x_r100 = np.linspace(-4, 4, 10000)\n",
    "\n",
    "plt.close()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figwidth(7)\n",
    "ax.plot(\n",
    "    laplace_asymmetric.ppf(x_r1, kappa_la, loc=loc_la, scale=scale_la),\n",
    "    # quantiles of Laplace distribution using the parameter estimates from our data\n",
    "    np.quantile(df_transactions2[\"residual_oob\"], x_r1),\n",
    "    \"k\",\n",
    ")\n",
    "\n",
    "# actual quantiles of our data\n",
    "ax.plot(x_r100, x_r100, \"--\")\n",
    "\n",
    "# Quantile of laplace distribution\n",
    "ax.axvline(x=laplace_asymmetric.ppf(0.01, kappa_la, loc=loc_la, scale=scale_la), color='red', linestyle='--')\n",
    "ax.axvline(x=laplace_asymmetric.ppf(0.999, kappa_la, loc=loc_la, scale=scale_la), color='green', linestyle='--')\n",
    "\n",
    "# aesthetics\n",
    "ax.set_xlim(-2.5, 2.5)\n",
    "ax.set_ylim(-4.5, 4)\n",
    "plt.annotate(\n",
    "    'P01',\n",
    "    (laplace_asymmetric.ppf(0.009, kappa_la, loc=loc_la, scale=scale_la), 0.9),\n",
    "    xycoords=('data', 'axes fraction'),\n",
    "    ha='right',\n",
    "    va='top',\n",
    "    rotation=90)\n",
    "plt.annotate(\n",
    "    'P99.9',\n",
    "    (laplace_asymmetric.ppf(0.9985, kappa_la, loc=loc_la, scale=scale_la), 0.9),\n",
    "    xycoords=('data', 'axes fraction'),\n",
    "    ha='right',\n",
    "    va='top',\n",
    "    rotation=90)\n",
    "ax.set_xlabel(\"Quantiles of asymmetric Laplace distribution\")\n",
    "ax.set_ylabel(\"Quantiles of OOB residuals distribution\")\n",
    "\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a8782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute thresholds\n",
    "th_low  = laplace_asymmetric.ppf(0.01, kappa_la, loc=loc_la, scale=scale_la)\n",
    "th_high = laplace_asymmetric.ppf(0.999, kappa_la, loc=loc_la, scale=scale_la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fc7c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938db0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
